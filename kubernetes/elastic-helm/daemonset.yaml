mode: daemonset
presets:
  logsCollection:
    enabled: true
  hostMetrics:
    enabled: true
  kubeletMetrics:
    enabled: true
  kubernetesAttributes:
    enabled: true

image:
  repository: docker.elastic.co/beats/elastic-agent
  tag: 8.16.0-SNAPSHOT

securityContext:
  runAsUser: 0
  runAsGroup: 0

extraEnvs:
  - name: ELASTIC_AGENT_OTEL
    value: "true"
  - name: ELASTIC_ENDPOINT
    valueFrom:
      secretKeyRef:
        name: elastic-secret-ds
        key: elastic_endpoint
  - name: ELASTIC_API_KEY
    valueFrom:
      secretKeyRef:
        name: elastic-secret-ds
        key: elastic_api_key
  - name: K8S_NODE_NAME
    valueFrom:
      fieldRef:
        fieldPath: spec.nodeName

# kubeletstats additional rules for Node metrics
clusterRole:
  create: true
  rules:
    - apiGroups:
        - ""
      resources:
        - nodes/proxy
      verbs:
        - get
    - apiGroups:
        - ""
      resources:
        - nodes
      verbs:
        - get
        - watch
        - list

config:
  extensions:
    health_check:
      endpoint: ${env:MY_POD_IP}:13133
  exporters:
    debug:
      verbosity: basic
    elasticsearch:
      endpoints:
      - ${env:ELASTIC_ENDPOINT}
      api_key: ${env:ELASTIC_API_KEY}
      logs_dynamic_index:
        enabled: true
      metrics_dynamic_index:
        enabled: true
      mapping:
        mode: ecs
    elasticsearch/otlp:
      endpoints:
      - ${env:ELASTIC_ENDPOINT}
      api_key: ${env:ELASTIC_API_KEY}
      logs_dynamic_index:
        enabled: true
      mapping:
        mode: otel
  processors:
    batch: {}
    elasticinframetrics:
      add_system_metrics: true
      add_k8s_metrics: true
    resourcedetection/eks:
      detectors: [env, eks]
      timeout: 15s
      override: true
      eks:
        resource_attributes:
          k8s.cluster.name:
            enabled: true
    resourcedetection/gcp:
      detectors: [env, gcp]
      timeout: 2s
      override: true
    resource/k8s:
      attributes:
        - key: service.name
          from_attribute: app.label.component
          action: insert
    attributes/dataset:
      actions:
        - key: event.dataset
          from_attribute: data_stream.dataset
          action: upsert
    resource/cloud:
      attributes:
        - key: cloud.instance.id
          from_attribute: host.id
          action: insert
    resource/demo:
      attributes:
        - key: deployment.environment
          value: "opentelemetry-demo"
          action: upsert
    resource/process:
      attributes:
        - key: process.executable.name
          action: delete
        - key: process.executable.path
          action: delete
    resourcedetection/system:
      detectors: ["system", "ec2"]
      system:
        hostname_sources: [ "os" ]
        resource_attributes:
          host.name:
            enabled: true
          host.id:
            enabled: false
          host.arch:
            enabled: true
          host.ip:
            enabled: true
          host.mac:
            enabled: true
          host.cpu.vendor.id:
            enabled: true
          host.cpu.family:
            enabled: true
          host.cpu.model.id:
            enabled: true
          host.cpu.model.name:
            enabled: true
          host.cpu.stepping:
            enabled: true
          host.cpu.cache.l2.size:
            enabled: true
          os.description:
            enabled: true
          os.type:
            enabled: true
      ec2:
        resource_attributes:
          host.name:
            enabled: false
          host.id:
            enabled: true
    k8sattributes:
      filter:
        node_from_env_var: K8S_NODE_NAME
      passthrough: false
      pod_association:
        - sources:
            - from: resource_attribute
              name: k8s.pod.ip
        - sources:
            - from: resource_attribute
              name: k8s.pod.uid
        - sources:
            - from: connection
      extract:
        metadata:
          - "k8s.namespace.name"
          - "k8s.deployment.name"
          - "k8s.statefulset.name"
          - "k8s.daemonset.name"
          - "k8s.cronjob.name"
          - "k8s.job.name"
          - "k8s.node.name"
          - "k8s.pod.name"
          - "k8s.pod.uid"
          - "k8s.pod.start_time"
        labels:
          - tag_name: app.label.component
            key: app.kubernetes.io/component
            from: pod
    transform/parse_nginx_ingress_error/log:
      error_mode: ignore
      log_statements:
        - context: log
          conditions:
              # ^[EWF]: Matches logs starting with E (Error), W (Warning), or F (Fatal).
              # \d{4}: Matches the four digits after the log level (representing the date, like 1215 for December 15).
              # .+: Matches the rest of the log line (the message part, without needing specific timestamp or file format).
            - IsMatch(body, "^[EWF]\\d{4} .+")
          statements:
            - merge_maps(attributes, ExtractGrokPatterns(body, "%{LOG_LEVEL:log.level}%{MONTHNUM}%{MONTHDAY} %{HOUR}:%{MINUTE}:%{SECOND}\\.%{MICROS}%{SPACE}%{NUMBER:nginx_ingress_controller.error.thread_id} %{SOURCE_FILE:nginx_ingress_controller.error.source.file}:%{NUMBER:nginx_ingress_controller.error.source.line_number}\\] %{GREEDYMULTILINE:message}", true, ["LOG_LEVEL=[A-Z]", "MONTHNUM=(0[1-9]|1[0-2])", "MONTHDAY=(0[1-9]|[12][0-9]|3[01])", "HOUR=([01][0-9]|2[0-3])", "MINUTE=[0-5][0-9]", "SECOND=[0-5][0-9]", "MICROS=[0-9]{6}", "SOURCE_FILE=[^:]+", "GREEDYMULTILINE=(.|\\n)*"]), "upsert")

            - set(attributes["data_stream.dataset"], "nginx_ingress_controller.error")

            # LogRecord event: https://github.com/open-telemetry/semantic-conventions/pull/982
            - set(attributes["event.name"], "nginx.ingress.controller.error")

    transform/parse_nginx_ingress_access/log:
      error_mode: ignore
      log_statements:
        - context: log
          conditions:
              #     # ^([0-9a-fA-F:.]+): Matches the remote address (IPv4 or IPv6 format).
              #     # [^ ]+: Matches the remote user (including the hyphen for missing user).
              #     # .*[0-9a-fA-F]+$: Ensures the log line ends with a hexadecimal string (request ID).
            - IsMatch(body, "^([0-9a-fA-F:.]+) - [^ ]+ .*[0-9a-fA-F]+$")
          statements:
            # Log format: https://github.com/kubernetes/ingress-nginx/blob/nginx-0.30.0/docs/user-guide/nginx-configuration/log-format.md
            # Based on https://github.com/elastic/integrations/blob/main/packages/nginx_ingress_controller/data_stream/access/elasticsearch/ingest_pipeline/default.yml
            - merge_maps(attributes, ExtractGrokPatterns(body, "(%{NGINX_HOST} )?\"?(?:%{NGINX_ADDRESS_LIST:nginx_ingress_controller.access.remote_ip_list}|%{NOTSPACE:source.address}) - (-|%{DATA:user.name}) \\[%{HTTPDATE:nginx_ingress_controller.access.time}\\] \"%{DATA:nginx_ingress_controller.access.info}\" %{NUMBER:http.response.status_code:long} %{NUMBER:http.response.body.size:long} \"(-|%{DATA:http.request.referrer})\" \"(-|%{DATA:user_agent.original})\" %{NUMBER:http.request.size:long} %{NUMBER:http.request.time:double} \\[%{DATA:upstream.name}\\] \\[%{DATA:upstream.alternative_name}\\] (%{UPSTREAM_ADDRESS_LIST:upstream.address}|-) (%{UPSTREAM_RESPONSE_SIZE_LIST:upstream.response.size_list}|-) (%{UPSTREAM_RESPONSE_TIME_LIST:upstream.response.time_list}|-) (%{UPSTREAM_RESPONSE_STATUS_CODE_LIST:upstream.response.status_code_list}|-) %{GREEDYDATA:http.request.id}", true, ["NGINX_HOST=(?:%{IP:destination.ip}|%{NGINX_NOTSEPARATOR:destination.domain})(:%{NUMBER:destination.port})?", "NGINX_NOTSEPARATOR=[^\t ,:]+", "NGINX_ADDRESS_LIST=(?:%{IP}|%{WORD}) (\"?,?\\s*(?:%{IP}|%{WORD}))*", "UPSTREAM_ADDRESS_LIST=(?:%{IP}(:%{NUMBER})?)(\"?,?\\s*(?:%{IP}(:%{NUMBER})?))*", "UPSTREAM_RESPONSE_SIZE_LIST=(?:%{NUMBER})(\"?,?\\s*(?:%{NUMBER}))*", "UPSTREAM_RESPONSE_TIME_LIST=(?:%{NUMBER})(\"?,?\\s*(?:%{NUMBER}))*", "UPSTREAM_RESPONSE_STATUS_CODE_LIST=(?:%{NUMBER})(\"?,?\\s*(?:%{NUMBER}))*", "IP=(?:\\[?%{IPV6}\\]?|%{IPV4})"]), "upsert")


            - merge_maps(attributes, ExtractGrokPatterns(attributes["nginx_ingress_controller.access.info"], "%{WORD:http.request.method} %{DATA:url.original} HTTP/%{NUMBER:http.version}", true), "upsert")
            - delete_key(attributes, "nginx_ingress_controller.access.info")

            # Extra URL parsing
            - merge_maps(attributes, URL(attributes["url.original"]), "upsert")
            - set(attributes["url.domain"], attributes["destination.domain"])

            # set protocol name
            - set(attributes["network.protocol.name"], "http")

            # tmp
            - set(attributes["data_stream.dataset"], "nginx_ingress_controller.access")

            # LogRecord event: https://github.com/open-telemetry/semantic-conventions/pull/982
            - set(attributes["event.name"], "nginx.ingress.controller.access")
            - set(attributes["event.timestamp"], attributes["nginx_ingress_controller.access.time"])
            - delete_key(attributes, "nginx_ingress_controller.access.time")

        - context: log
          conditions:
              # Extract user agent when not empty
            - attributes["user_agent.original"] != nil
          statements:
            # Extract UserAgent
            # TODO: UserAgent OTTL function does not provide os specific metadata yet: https://github.com/open-telemetry/opentelemetry-collector-contrib/issues/35458
            - merge_maps(attributes, UserAgent(attributes["user_agent.original"]), "upsert")

        - context: log
          conditions:
            - attributes["upstream.response.time_list"] != nil
          statements:
            # Extract comma separated list
            # TODO: We would like to get the sum over all upstream.response.time_list values instead of providing a slice with all the values
            - set(attributes["upstream.response.time"], Split(attributes["upstream.response.time_list"], ","))
            - delete_key(attributes, "upstream.response.time_list")

        - context: log
          conditions:
            - attributes["upstream.response.size_list"] != nil
          statements:
            # Extract comma separated list
            # TODO: We would like to get the Last upstream.response.size_list value instead of providing a slice with all the values
            # See: https://github.com/elastic/integrations/blob/main/packages/nginx_ingress_controller/data_stream/access/elasticsearch/ingest_pipeline/default.yml#L94b
            - set(attributes["upstream.response.size"], Split(attributes["upstream.response.size_list"], ","))
            - delete_key(attributes, "upstream.response.size_list")

        - context: log
          conditions:
            - attributes["upstream.response.status_code_list"] != nil
          statements:
            # Extract comma separated list
            # TODO: We would like to get the Last upstream.response.status_code_list value instead of providing a slice with all the values
            - set(attributes["upstream.response.status_code"], Split(attributes["upstream.response.status_code_list"], ","))
            - delete_key(attributes, "upstream.response.status_code_list")
  receivers:
    otlp: null
    jaeger: null
    prometheus: null
    zipkin: null
    filelog:
      retry_on_failure:
        enabled: true
      start_at: end
      exclude:
      # exlude collector logs
      - /var/log/pods/*/opentelemetry-collector/*.log
      include:
      - /var/log/pods/*/*/*.log
      include_file_name: false
      include_file_path: true
      operators:
      - id: container-parser
        type: container
    hostmetrics:
      collection_interval: 10s
      root_path: /hostfs
      scrapers:
        cpu:
          metrics:
            system.cpu.utilization:
              enabled: true
            system.cpu.logical.count:
              enabled: true
        memory:
          metrics:
            system.memory.utilization:
              enabled: true
        process:
          mute_process_exe_error: true
          mute_process_io_error: true
          mute_process_user_error: true
          metrics:
            process.threads:
              enabled: true
            process.open_file_descriptors:
              enabled: true
            process.memory.utilization:
              enabled: true
            process.disk.operations:
              enabled: true
        network:
        processes:
        load:
        disk:
        filesystem:
          exclude_mount_points:
            mount_points:
              - /dev/*
              - /proc/*
              - /sys/*
              - /run/k3s/containerd/*
              - /var/lib/docker/*
              - /var/lib/kubelet/*
              - /snap/*
            match_type: regexp
          exclude_fs_types:
            fs_types:
              - autofs
              - binfmt_misc
              - bpf
              - cgroup2
              - configfs
              - debugfs
              - devpts
              - devtmpfs
              - fusectl
              - hugetlbfs
              - iso9660
              - mqueue
              - nsfs
              - overlay
              - proc
              - procfs
              - pstore
              - rpc_pipefs
              - securityfs
              - selinuxfs
              - squashfs
              - sysfs
              - tracefs
            match_type: strict
    kubeletstats:
      auth_type: serviceAccount
      collection_interval: 20s
      endpoint: ${env:K8S_NODE_NAME}:10250
      node: '${env:K8S_NODE_NAME}'
      # Required to work for all CSPs without an issue
      insecure_skip_verify: true
      k8s_api_config:
        auth_type: serviceAccount
      metrics:
        k8s.pod.memory.node.utilization:
          enabled: true
        k8s.pod.cpu.node.utilization:
          enabled: true
        k8s.container.cpu_limit_utilization:
          enabled: true
        k8s.pod.cpu_limit_utilization:
          enabled: true
        k8s.container.cpu_request_utilization:
          enabled: true
        k8s.container.memory_limit_utilization:
          enabled: true
        k8s.pod.memory_limit_utilization:
          enabled: true
        k8s.container.memory_request_utilization:
          enabled: true
        k8s.node.uptime:
          enabled: true
        k8s.node.cpu.usage:
          enabled: true
        k8s.pod.cpu.usage:
          enabled: true
      extra_metadata_labels:
        - container.id
  service:
    extensions: [health_check]
    pipelines:
      logs:
        receivers: [filelog]
        processors: [batch, k8sattributes, resourcedetection/system, resourcedetection/eks, resourcedetection/gcp, resource/demo, resource/k8s, resource/cloud,transform/parse_nginx_ingress_access/log, transform/parse_nginx_ingress_error/log]
        exporters: [debug, elasticsearch/otlp]
      metrics:
        receivers: [hostmetrics, kubeletstats]
        processors: [batch, k8sattributes, elasticinframetrics, resourcedetection/system, resource/demo, resourcedetection/eks, resourcedetection/gcp, resource/k8s, resource/cloud, attributes/dataset, resource/process]
        exporters: [debug, elasticsearch]
      traces: null
    telemetry:
      metrics:
        address: ${env:MY_POD_IP}:8888
